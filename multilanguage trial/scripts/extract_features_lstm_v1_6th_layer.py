import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import torch
import librosa
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from transformers import HubertModel, Wav2Vec2FeatureExtractor
from tqdm import tqdm
import random

# âœ… åŠ è½½ HuBERT é¢„è®­ç»ƒæ¨¡å‹
processor = Wav2Vec2FeatureExtractor.from_pretrained("facebook/hubert-base-ls960")
hubert = HubertModel.from_pretrained(
    "facebook/hubert-base-ls960",
    output_hidden_states=True  # ğŸŸ¢ å¯ç”¨ä¸­é—´å±‚è¾“å‡º
).eval().to("cuda" if torch.cuda.is_available() else "cpu")

# âœ… æ ‡ç­¾æ˜ å°„
label_map = {"happy": 0, "sad": 1, "surprised": 2, "calm": 3}
label_names = {v: k for k, v in label_map.items()}

# âœ… è·¯å¾„è®¾ç½®
data_dir = "./data_v1"
save_dir = "./features_lstm_v1"
os.makedirs(save_dir, exist_ok=True)

# âœ… ç”¨äºå¯è§†åŒ–çš„é‡‡æ ·å¸§å’Œæ ‡ç­¾ï¼ˆæ¯ç±»ä¸è¶…è¿‡ 50 æ¡å¸§ï¼‰
tsne_features = []
tsne_labels = {0: [], 1: [], 2: [], 3: []}  # æƒ…ç»ª â†’ å¯¹åº”å¸§

print("ğŸš€ HuBERT is extracting frame-level features...\n")
for emotion in os.listdir(data_dir):
    emo_path = os.path.join(data_dir, emotion)
    if not os.path.isdir(emo_path): continue

    if emotion not in label_map:
        print(f"âš ï¸ Skipping unknown emotion: {emotion}")
        continue

    label = label_map[emotion]
    print(f"ğŸ§ Processing emotion: {emotion}")
    file_list = [f for f in os.listdir(emo_path) if f.endswith(".wav")]

    for wav in tqdm(file_list, desc=f"{emotion}", ncols=80):
        wav_path = os.path.join(emo_path, wav)
        waveform, _ = librosa.load(wav_path, sr=16000)

        # âœ… æå–å¸§çº§ç‰¹å¾ [1, T, 768] â†’ [T, 768]
        inputs = processor(waveform, sampling_rate=16000, return_tensors="pt", padding=True)
        with torch.no_grad():
            hidden_states = hubert(inputs.input_values.to(hubert.device), output_hidden_states=True).hidden_states[6]
            feature = hidden_states.squeeze(0).cpu()  # [T, 768]

        # âœ… ä¿å­˜ .pt ç‰¹å¾
        save_path = os.path.join(save_dir, wav.replace(".wav", ".pt"))
        torch.save({"feature": feature, "label": label}, save_path)

        # âœ… å¯è§†åŒ–é‡‡æ ·å¸§ï¼ˆæ¯ç±»æœ€å¤šä¿ç•™ 50 ä¸ªå¸§ï¼‰
        if len(tsne_labels[label]) < 50:
            frame_indices = random.sample(range(feature.size(0)), min(5, feature.size(0)))
            for idx in frame_indices:
                tsne_features.append(feature[idx].numpy())
                tsne_labels[label].append(1)

print(f"\nâœ… All features saved to: {save_dir}")
print("ğŸ§  Collected {} total frame-level features for t-SNE.".format(len(tsne_features)))

# âœ… ç‰¹å¾å¯è§†åŒ–ï¼ˆt-SNEï¼‰
print("\nğŸ¨ Feature visualization (t-SNE)...")
tsne = TSNE(n_components=2, random_state=42, perplexity=30)
reduced = tsne.fit_transform(np.array(tsne_features))

# âœ… ç»˜å›¾
plt.figure(figsize=(8, 6))
colors = ['red', 'blue', 'green', 'orange']
for label_id, color in zip(range(4), colors):
    indices = [i for i, feat_label in enumerate(tsne_labels[label_id]) if feat_label == 1]
    if indices:
        reduced_subset = reduced[sum(len(tsne_labels[i]) for i in range(label_id)):sum(len(tsne_labels[i]) for i in range(label_id + 1))]
        plt.scatter(reduced_subset[:, 0], reduced_subset[:, 1], label=label_names[label_id], color=color, alpha=0.7, s=30)

plt.title("t-SNE Visualization of HuBERT Frame-level Features")
plt.xlabel("Dim 1")
plt.ylabel("Dim 2")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("tsne_visualization_lstm_v1.png")
plt.show()

print("ğŸ“ t-SNE plot saved as tsne_visualization_lstm_v1.png")
