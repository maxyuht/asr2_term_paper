# scripts/split_dataset_balanced.py

import os
import random
import shutil
import torch
from collections import defaultdict
import pandas as pd

# è®¾ç½®è·¯å¾„
features_dir = "./features_v3"
splits_dir = "./splits_v3"
split_ratio = {"train": 0.7, "val": 0.15, "test": 0.15}

# åˆ›å»º split æ–‡ä»¶å¤¹
for split in split_ratio:
    os.makedirs(os.path.join(splits_dir, split), exist_ok=True)

# è¯»å– .pt æ–‡ä»¶ï¼Œå¹¶æŒ‰ label åˆ†ç±»
label_to_files = defaultdict(list)

print("ğŸ“‚ Reading audio feature...")
for file in os.listdir(features_dir):
    if file.endswith(".pt"):
        path = os.path.join(features_dir, file)
        try:
            data = torch.load(path)
            label = int(data["label"])  # ä»æ–‡ä»¶ä¸­è·å–æƒ…ç»ªæ ‡ç­¾
            label_to_files[label].append(file)
        except Exception as e:
            print(f" Failed: {file}, error: {e}")

# å¼€å§‹åˆ’åˆ†
split_stats = defaultdict(lambda: defaultdict(int))

print("\n Spliting the datas...")
for label, files in label_to_files.items():
    random.shuffle(files)
    n_total = len(files)
    n_train = int(split_ratio["train"] * n_total)
    n_val = int(split_ratio["val"] * n_total)
    n_test = n_total - n_train - n_val  # é˜²æ­¢æµ®ç‚¹è¯¯å·®

    splits = {
        "train": files[:n_train],
        "val": files[n_train:n_train + n_val],
        "test": files[n_train + n_val:]
    }

    for split_name, split_files in splits.items():
        for f in split_files:
            src = os.path.join(features_dir, f)
            dst = os.path.join(splits_dir, split_name, f)
            shutil.copy(src, dst)
            split_stats[split_name][label] += 1

# è¾“å‡ºç»Ÿè®¡ç»“æœ
df = pd.DataFrame(split_stats).fillna(0).astype(int)
df.index.name = "Emotion Label"
df.columns.name = "Subset"
print("\n Data split result:")
print(df)

# å¯é€‰ï¼šä¿å­˜ç»Ÿè®¡åˆ° CSV
df.to_csv("split_stats_v3.csv")
